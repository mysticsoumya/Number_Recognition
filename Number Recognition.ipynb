{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "82418877-8407-45ef-9b76-86ca80e07abf",
    "_execution_state": "idle",
    "_uuid": "483f57b296f8d69647bbec1154acfa2da3c6fc2f"
   },
   "source": [
    "## Number Recognition\n",
    "\n",
    "Handwritten digit recognition system not only detects scanned images of handwritten digits.Handwritten digit recognition using MNIST dataset is a major project made with the help of Neural Network. It basically detects the scanned images of handwritten digits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "440129fa-bb2d-47b8-9415-714467d98743",
    "_execution_state": "idle",
    "_uuid": "44f63ca7fc70094c75598c27b433b316ea406237"
   },
   "source": [
    "Importing key libraries, and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "55ec59e1-8a8c-42d2-8ccc-b6d95ea198b4",
    "_execution_state": "busy",
    "_uuid": "a6d625ede9e19ac1f146a5f63d6ca19c4b98e20c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI_ML\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1212)\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "daa0805e-e1dd-4806-b2db-ff0124febe7d",
    "_execution_state": "busy",
    "_uuid": "be0a7acbb3bfc83fd3103b4a401337aafe57c00d"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE DATA FOR NEURAL NETWORK\n",
    "Y_train = df_train[\"label\"]\n",
    "X_train = df_train.drop(labels = [\"label\"],axis = 1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = df_test / 255.0\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x450 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# PREVIEW IMAGES\n",
    "plt.figure(figsize=(15,4.5))\n",
    "for i in range(30):  \n",
    "    plt.subplot(3, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape((28,28)),cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace=-0.1, hspace=-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "dfae6a31-23ea-4d88-9fcd-06b8b705b614",
    "_execution_state": "busy",
    "_uuid": "0f7bfb5923e5b4ed5a5149c007a2cd39cb9b8282"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head() # 784 features, 1 label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "45bd232a-4000-4a06-a3ed-0be9f993746c",
    "_execution_state": "idle",
    "_uuid": "f0970dcbc0b6791dc44936d8d63e6985dfb6960c"
   },
   "source": [
    "## Splitting into training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "bb78680a-ce50-4ee9-a77f-265b9ee38aee",
    "_execution_state": "busy",
    "_uuid": "16e39b5512ed29c8f9d7db51331693e4689ce306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "df_features = df_train.iloc[:, 1:785]\n",
    "df_label = df_train.iloc[:, 0]\n",
    "\n",
    "X_test = df_test.iloc[:, 0:784]\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "a3fb0b37-1edf-42bd-b951-86f254b78fc1",
    "_execution_state": "busy",
    "_uuid": "a98808f6188e9c44741ad2b5c25a894106406dfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, \n",
    "                                                test_size = 0.2,\n",
    "                                                random_state = 1212)\n",
    "\n",
    "X_train = X_train.values.reshape(33600, 784) #(33600, 784)\n",
    "X_cv = X_cv.values.reshape(8400, 784) #(8400, 784)\n",
    "\n",
    "X_test = X_test.values.reshape(28000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4486ba9e-b8b3-4f09-a597-3d5e6bbd6c1c",
    "_execution_state": "idle",
    "_uuid": "9a10a6e1aae9645a7c3e5a703d78d9c3b096f6d3"
   },
   "source": [
    "## Data cleaning, normalization and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "4d0e07b5-28dd-42f1-b425-6414aea90cde",
    "_execution_state": "busy",
    "_uuid": "cc2daf9f099fb62e3b470f913349428ef396b75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 255)\n"
     ]
    }
   ],
   "source": [
    "print((min(X_train[1]), max(X_train[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60b333cc-a76e-4713-97f5-a9095e27e43b",
    "_execution_state": "idle",
    "_uuid": "11d4f22158c013b3f028f5c11340b4a4b7291d1e"
   },
   "source": [
    "As the pixel intensities are currently between the range of 0 and 255, we proceed to normalize the features, using broadcasting. In addition, we proceed to convert our labels from a class vector to binary One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "e9f8eaa0-c77e-4510-9ff1-bb56e1d5f76d",
    "_execution_state": "busy",
    "_uuid": "c24261ffd2384078a836a909ea4839a31d51dd66"
   },
   "outputs": [],
   "source": [
    "# Feature Normalization \n",
    "X_train = X_train.astype('float32'); X_cv= X_cv.astype('float32'); X_test = X_test.astype('float32')\n",
    "X_train /= 255; X_cv /= 255; X_test /= 255\n",
    "\n",
    "# Convert labels to One Hot Encoded\n",
    "num_digits = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_digits)\n",
    "y_cv = keras.utils.to_categorical(y_cv, num_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "6667ca35-44ff-43f3-b88b-27b787be4ee0",
    "_execution_state": "busy",
    "_uuid": "3fdf37a538504f4e5288cbb8b70a719c2689caca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Printing 2 examples of labels after conversion\n",
    "print(y_train[0]) # 2\n",
    "print(y_train[3]) # 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d4e437c-12ea-4bad-a580-5504e8a77da0",
    "_execution_state": "idle",
    "_uuid": "0776b5f2aff1ebb6f12c2a9ee8e93013c690caf6"
   },
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f441392-a707-499c-8816-00c8aa1a7757",
    "_execution_state": "idle",
    "_uuid": "064d83d74bf2e0842b21dcb3cc93f8427b04b6ea"
   },
   "source": [
    "Model 1: Simple Neural Network with 4 layers (300, 100, 100, 200)\n",
    "\n",
    "In our first model, we will use the Keras library to train a neural network with the activation function set as ReLu. To determine which class to output, we will rely on the SoftMax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "be9af3d4-ddac-4f85-945f-bd1cdf09fc15",
    "_execution_state": "busy",
    "_uuid": "b88da407b6dab83e54b5380e0e62459577949932"
   },
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "74eac473-a6cb-4356-a982-ef3cb6c971de",
    "_execution_state": "busy",
    "_uuid": "f97a558010d88407363bbb08fa00e7c87a3d6ceb"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "bf09781e-6376-4f2d-a872-6292d466f657",
    "_execution_state": "busy",
    "_uuid": "aaf8fe1cd6cb32675f0ed5009d7bc31d6f71e4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " Hidden_Layer_1 (Dense)      (None, 300)               235500    \n",
      "                                                                 \n",
      " Hidden_Layer_2 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " Hidden_Layer_3 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_Layer_4 (Dense)      (None, 200)               20200     \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 297910 (1.14 MB)\n",
      "Trainable params: 297910 (1.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model = Model(Inp, output)\n",
    "model.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "906807f1-ed62-4dee-a423-5f15842fb28f",
    "_execution_state": "busy",
    "_uuid": "c4ea7858fbdf41308dcdb5d373af11484d5b5140"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "# Insert Hyperparameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "sgd = optimizers.SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "5678ce6d-58eb-4394-9a77-b67c94c2ca4f",
    "_execution_state": "busy",
    "_uuid": "775193de659c41c949495a2afa3b14024a2536a7"
   },
   "outputs": [],
   "source": [
    "# We rely on the plain vanilla Stochastic Gradient Descent as our optimizing methodology\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "1a547d04-6aeb-4c76-8fbc-7fbca1b50b2a",
    "_execution_state": "busy",
    "_uuid": "4960dfa65394fb0314ce9cb7af63d48709a39d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 - 4s - loss: 1.8452 - accuracy: 0.4704 - val_loss: 0.9932 - val_accuracy: 0.7792 - 4s/epoch - 12ms/step\n",
      "Epoch 2/20\n",
      "336/336 - 3s - loss: 0.6285 - accuracy: 0.8360 - val_loss: 0.4508 - val_accuracy: 0.8749 - 3s/epoch - 8ms/step\n",
      "Epoch 3/20\n",
      "336/336 - 3s - loss: 0.4046 - accuracy: 0.8851 - val_loss: 0.3553 - val_accuracy: 0.8957 - 3s/epoch - 10ms/step\n",
      "Epoch 4/20\n",
      "336/336 - 3s - loss: 0.3378 - accuracy: 0.9011 - val_loss: 0.3198 - val_accuracy: 0.9068 - 3s/epoch - 8ms/step\n",
      "Epoch 5/20\n",
      "336/336 - 2s - loss: 0.2997 - accuracy: 0.9121 - val_loss: 0.2880 - val_accuracy: 0.9182 - 2s/epoch - 7ms/step\n",
      "Epoch 6/20\n",
      "336/336 - 2s - loss: 0.2706 - accuracy: 0.9190 - val_loss: 0.2627 - val_accuracy: 0.9229 - 2s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "336/336 - 4s - loss: 0.2478 - accuracy: 0.9266 - val_loss: 0.2489 - val_accuracy: 0.9271 - 4s/epoch - 11ms/step\n",
      "Epoch 8/20\n",
      "336/336 - 2s - loss: 0.2290 - accuracy: 0.9314 - val_loss: 0.2317 - val_accuracy: 0.9356 - 2s/epoch - 7ms/step\n",
      "Epoch 9/20\n",
      "336/336 - 2s - loss: 0.2122 - accuracy: 0.9373 - val_loss: 0.2170 - val_accuracy: 0.9367 - 2s/epoch - 7ms/step\n",
      "Epoch 10/20\n",
      "336/336 - 3s - loss: 0.1971 - accuracy: 0.9421 - val_loss: 0.2089 - val_accuracy: 0.9414 - 3s/epoch - 8ms/step\n",
      "Epoch 11/20\n",
      "336/336 - 2s - loss: 0.1852 - accuracy: 0.9457 - val_loss: 0.1963 - val_accuracy: 0.9431 - 2s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "336/336 - 2s - loss: 0.1734 - accuracy: 0.9493 - val_loss: 0.1884 - val_accuracy: 0.9464 - 2s/epoch - 6ms/step\n",
      "Epoch 13/20\n",
      "336/336 - 2s - loss: 0.1635 - accuracy: 0.9525 - val_loss: 0.1829 - val_accuracy: 0.9464 - 2s/epoch - 7ms/step\n",
      "Epoch 14/20\n",
      "336/336 - 3s - loss: 0.1542 - accuracy: 0.9545 - val_loss: 0.1719 - val_accuracy: 0.9486 - 3s/epoch - 8ms/step\n",
      "Epoch 15/20\n",
      "336/336 - 3s - loss: 0.1452 - accuracy: 0.9575 - val_loss: 0.1653 - val_accuracy: 0.9510 - 3s/epoch - 10ms/step\n",
      "Epoch 16/20\n",
      "336/336 - 3s - loss: 0.1381 - accuracy: 0.9596 - val_loss: 0.1593 - val_accuracy: 0.9521 - 3s/epoch - 8ms/step\n",
      "Epoch 17/20\n",
      "336/336 - 3s - loss: 0.1307 - accuracy: 0.9613 - val_loss: 0.1569 - val_accuracy: 0.9533 - 3s/epoch - 10ms/step\n",
      "Epoch 18/20\n",
      "336/336 - 2s - loss: 0.1240 - accuracy: 0.9633 - val_loss: 0.1529 - val_accuracy: 0.9530 - 2s/epoch - 7ms/step\n",
      "Epoch 19/20\n",
      "336/336 - 3s - loss: 0.1180 - accuracy: 0.9656 - val_loss: 0.1501 - val_accuracy: 0.9552 - 3s/epoch - 8ms/step\n",
      "Epoch 20/20\n",
      "336/336 - 3s - loss: 0.1121 - accuracy: 0.9672 - val_loss: 0.1430 - val_accuracy: 0.9560 - 3s/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, y_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = training_epochs,\n",
    "                     verbose = 2,\n",
    "                     validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2fee2dfc-23d2-480f-918e-54fb5386c4ea",
    "_execution_state": "idle",
    "_uuid": "6121bf7f8adbeaf85b3aef6167444b555b920440"
   },
   "source": [
    "Using a 4 layer neural network with:\n",
    "\n",
    "1. 20 training epochs\n",
    "2. A training batch size of 100\n",
    "3. Hidden layers set as (300, 100, 100, 200)\n",
    "4. Learning rate of 0.1\n",
    "\n",
    "Achieved a training score of around 96-98% and a test score of around 95 - 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "4e7a2ba9-ac08-4355-a37f-2336220cfda7",
    "_execution_state": "busy",
    "_uuid": "3d9c3ffb9722b640ea0682e5826971045091db66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "# We rely on ADAM as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2 = Model(Inp, output)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "e4470ac7-6888-4b10-a4e5-8bd4e22301cf",
    "_execution_state": "busy",
    "_uuid": "7f94a2f9d7db89bf3fb28ecff64dbf7a496b0b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 - 5s - loss: 0.3411 - accuracy: 0.8999 - val_loss: 0.1608 - val_accuracy: 0.9545 - 5s/epoch - 14ms/step\n",
      "Epoch 2/20\n",
      "336/336 - 4s - loss: 0.1211 - accuracy: 0.9626 - val_loss: 0.1173 - val_accuracy: 0.9656 - 4s/epoch - 12ms/step\n",
      "Epoch 3/20\n",
      "336/336 - 4s - loss: 0.0774 - accuracy: 0.9752 - val_loss: 0.1039 - val_accuracy: 0.9677 - 4s/epoch - 11ms/step\n",
      "Epoch 4/20\n",
      "336/336 - 4s - loss: 0.0557 - accuracy: 0.9819 - val_loss: 0.1120 - val_accuracy: 0.9680 - 4s/epoch - 12ms/step\n",
      "Epoch 5/20\n",
      "336/336 - 5s - loss: 0.0463 - accuracy: 0.9850 - val_loss: 0.0870 - val_accuracy: 0.9750 - 5s/epoch - 13ms/step\n",
      "Epoch 6/20\n",
      "336/336 - 4s - loss: 0.0328 - accuracy: 0.9885 - val_loss: 0.1017 - val_accuracy: 0.9736 - 4s/epoch - 13ms/step\n",
      "Epoch 7/20\n",
      "336/336 - 5s - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.0958 - val_accuracy: 0.9752 - 5s/epoch - 16ms/step\n",
      "Epoch 8/20\n",
      "336/336 - 6s - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0994 - val_accuracy: 0.9750 - 6s/epoch - 17ms/step\n",
      "Epoch 9/20\n",
      "336/336 - 4s - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.1171 - val_accuracy: 0.9723 - 4s/epoch - 12ms/step\n",
      "Epoch 10/20\n",
      "336/336 - 4s - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.1209 - val_accuracy: 0.9739 - 4s/epoch - 12ms/step\n",
      "Epoch 11/20\n",
      "336/336 - 4s - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.1009 - val_accuracy: 0.9742 - 4s/epoch - 12ms/step\n",
      "Epoch 12/20\n",
      "336/336 - 4s - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.1076 - val_accuracy: 0.9757 - 4s/epoch - 12ms/step\n",
      "Epoch 13/20\n",
      "336/336 - 4s - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.1154 - val_accuracy: 0.9738 - 4s/epoch - 11ms/step\n",
      "Epoch 14/20\n",
      "336/336 - 4s - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.1408 - val_accuracy: 0.9715 - 4s/epoch - 11ms/step\n",
      "Epoch 15/20\n",
      "336/336 - 4s - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.1118 - val_accuracy: 0.9773 - 4s/epoch - 11ms/step\n",
      "Epoch 16/20\n",
      "336/336 - 4s - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.1274 - val_accuracy: 0.9756 - 4s/epoch - 11ms/step\n",
      "Epoch 17/20\n",
      "336/336 - 4s - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.1306 - val_accuracy: 0.9748 - 4s/epoch - 13ms/step\n",
      "Epoch 18/20\n",
      "336/336 - 4s - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.1306 - val_accuracy: 0.9744 - 4s/epoch - 12ms/step\n",
      "Epoch 19/20\n",
      "336/336 - 4s - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.1301 - val_accuracy: 0.9756 - 4s/epoch - 11ms/step\n",
      "Epoch 20/20\n",
      "336/336 - 4s - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1176 - val_accuracy: 0.9762 - 4s/epoch - 12ms/step\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      verbose = 2,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e5b9ec27-6585-4f51-be9e-9e86120f723a",
    "_execution_state": "idle",
    "_uuid": "beae0734aefb9f26144b556c753032b66fe99911"
   },
   "source": [
    "As it turns out, it does appear to be the case that the optimizer plays a crucial part in the validation score. In particular, the model which relies on 'Adam' as its optimizer tend to perform 1.5 - 2.5% better on average. Going forward, we will use 'Adam' as our optimizer of choice.\n",
    "\n",
    "What if we changed the learning rate from 0.1 to 0.01, or 0.5? Will it have any impact on the accuracy?\n",
    "Model 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "da528246-4223-42ff-af96-cd3419c34507",
    "_execution_state": "busy",
    "_uuid": "d2e88469ac4ed8ac19a195d71941178d8cdb7c32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2a = Model(Inp, output)\n",
    "\n",
    "model2a.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "847391bb-4640-4117-a35e-5593d823bbc4",
    "_execution_state": "busy",
    "_uuid": "8e397c8d027a4f27b1f72ac9333de51cbc335cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 - 5s - loss: 0.3428 - accuracy: 0.8998 - val_loss: 0.1711 - val_accuracy: 0.9480 - 5s/epoch - 16ms/step\n",
      "Epoch 2/20\n",
      "336/336 - 4s - loss: 0.1252 - accuracy: 0.9622 - val_loss: 0.1186 - val_accuracy: 0.9639 - 4s/epoch - 11ms/step\n",
      "Epoch 3/20\n",
      "336/336 - 4s - loss: 0.0854 - accuracy: 0.9729 - val_loss: 0.1027 - val_accuracy: 0.9704 - 4s/epoch - 11ms/step\n",
      "Epoch 4/20\n",
      "336/336 - 4s - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.0980 - val_accuracy: 0.9714 - 4s/epoch - 12ms/step\n",
      "Epoch 5/20\n",
      "336/336 - 4s - loss: 0.0451 - accuracy: 0.9857 - val_loss: 0.0992 - val_accuracy: 0.9729 - 4s/epoch - 11ms/step\n",
      "Epoch 6/20\n",
      "336/336 - 3s - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0920 - val_accuracy: 0.9736 - 3s/epoch - 10ms/step\n",
      "Epoch 7/20\n",
      "336/336 - 4s - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.1020 - val_accuracy: 0.9732 - 4s/epoch - 12ms/step\n",
      "Epoch 8/20\n",
      "336/336 - 5s - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.0979 - val_accuracy: 0.9751 - 5s/epoch - 14ms/step\n",
      "Epoch 9/20\n",
      "336/336 - 4s - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.1125 - val_accuracy: 0.9736 - 4s/epoch - 12ms/step\n",
      "Epoch 10/20\n",
      "336/336 - 4s - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.1137 - val_accuracy: 0.9748 - 4s/epoch - 12ms/step\n",
      "Epoch 11/20\n",
      "336/336 - 4s - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.1051 - val_accuracy: 0.9758 - 4s/epoch - 12ms/step\n",
      "Epoch 12/20\n",
      "336/336 - 4s - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.1215 - val_accuracy: 0.9725 - 4s/epoch - 11ms/step\n",
      "Epoch 13/20\n",
      "336/336 - 4s - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.1040 - val_accuracy: 0.9751 - 4s/epoch - 11ms/step\n",
      "Epoch 14/20\n",
      "336/336 - 4s - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.1319 - val_accuracy: 0.9710 - 4s/epoch - 11ms/step\n",
      "Epoch 15/20\n",
      "336/336 - 4s - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.1097 - val_accuracy: 0.9786 - 4s/epoch - 11ms/step\n",
      "Epoch 16/20\n",
      "336/336 - 4s - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0980 - val_accuracy: 0.9773 - 4s/epoch - 11ms/step\n",
      "Epoch 17/20\n",
      "336/336 - 4s - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.1104 - val_accuracy: 0.9788 - 4s/epoch - 13ms/step\n",
      "Epoch 18/20\n",
      "336/336 - 4s - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1277 - val_accuracy: 0.9746 - 4s/epoch - 11ms/step\n",
      "Epoch 19/20\n",
      "336/336 - 4s - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.1091 - val_accuracy: 0.9760 - 4s/epoch - 12ms/step\n",
      "Epoch 20/20\n",
      "336/336 - 4s - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1234 - val_accuracy: 0.9768 - 4s/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "history2a = model2a.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                        verbose = 2,\n",
    "                        validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "590e8fcc-b3da-41e7-984d-d5d53aa5cb81",
    "_execution_state": "idle",
    "_uuid": "42520a694b6caf71582c6d5aad5a8599d52e5096"
   },
   "source": [
    "Model 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "18ef2f7d-f9a6-4609-8fd4-7d98cb7bc82f",
    "_execution_state": "busy",
    "_uuid": "fbc0a1e06296ada3553c9328e48861645680bbf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.5\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2b = Model(Inp, output)\n",
    "\n",
    "model2b.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "ad3ac83b-a040-42ba-9d62-2203e62a82ec",
    "_execution_state": "busy",
    "_uuid": "c2e1a75c4a95acdfd3d5ce81af0c20bce995ca24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 [==============================] - 5s 12ms/step - loss: 0.3305 - accuracy: 0.9027 - val_loss: 0.1535 - val_accuracy: 0.9526\n",
      "Epoch 2/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1216 - accuracy: 0.9625 - val_loss: 0.1160 - val_accuracy: 0.9646\n",
      "Epoch 3/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0826 - accuracy: 0.9742 - val_loss: 0.0917 - val_accuracy: 0.9727\n",
      "Epoch 4/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0580 - accuracy: 0.9815 - val_loss: 0.0968 - val_accuracy: 0.9726\n",
      "Epoch 5/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.1141 - val_accuracy: 0.9671\n",
      "Epoch 6/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.1002 - val_accuracy: 0.9749\n",
      "Epoch 7/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.1001 - val_accuracy: 0.9720\n",
      "Epoch 8/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.1053 - val_accuracy: 0.9730\n",
      "Epoch 9/20\n",
      "336/336 [==============================] - 3s 10ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.1198 - val_accuracy: 0.9725\n",
      "Epoch 10/20\n",
      "336/336 [==============================] - 4s 10ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.1044 - val_accuracy: 0.9745\n",
      "Epoch 11/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.1147 - val_accuracy: 0.9732\n",
      "Epoch 12/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.1174 - val_accuracy: 0.9752\n",
      "Epoch 13/20\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.1096 - val_accuracy: 0.9781\n",
      "Epoch 14/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1159 - val_accuracy: 0.9750\n",
      "Epoch 15/20\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.1303 - val_accuracy: 0.9739\n",
      "Epoch 16/20\n",
      "336/336 [==============================] - 3s 10ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1141 - val_accuracy: 0.9764\n",
      "Epoch 17/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1096 - val_accuracy: 0.9781\n",
      "Epoch 18/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.1104 - val_accuracy: 0.9780\n",
      "Epoch 19/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1179 - val_accuracy: 0.9780\n",
      "Epoch 20/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.1163 - val_accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "history2b = model2b.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                            validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9189bb25-f243-4edf-a7a0-943ec633760d",
    "_execution_state": "idle",
    "_uuid": "a36eb4079d02e6d3997d107fc5e3dd3a452a0fc9"
   },
   "source": [
    "The accuracy, as measured by the 3 different learning rates 0.01, 0.1 and 0.5 are around 98%, 97% and 98% respectively. As there are no considerable gains by changing the learning rates, we stick with the default learning rate of 0.01.\n",
    "\n",
    "We proceed to fit a neural network with 5 hidden layers with the features in the hidden layer set as (300, 100, 100, 100, 200) respectively. To ensure that the two models are comparable, we will set the training epochs as 20, and the training batch size as 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "25d57f65-533c-432b-bd4a-a3127101d4bb",
    "_execution_state": "busy",
    "_uuid": "c19270be516858cca76b3479417e4017877896b1"
   },
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 100\n",
    "n_hidden_5 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "d179df94-04b5-4d1e-ab7f-882a72442837",
    "_execution_state": "busy",
    "_uuid": "c919e5d20e55f0c86152efbb729feeb0292abf0a"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "x = Dense(n_hidden_5, activation='relu', name = \"Hidden_Layer_5\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "04f2f013-41ee-48a7-9204-cfe8b748e09c",
    "_execution_state": "busy",
    "_uuid": "db189665726670192df8ed9e9758e908821f629b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " Hidden_Layer_1 (Dense)      (None, 300)               235500    \n",
      "                                                                 \n",
      " Hidden_Layer_2 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " Hidden_Layer_3 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_Layer_4 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_Layer_5 (Dense)      (None, 200)               20200     \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 308010 (1.17 MB)\n",
      "Trainable params: 308010 (1.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '7' layers - input layer, 5 hidden layer and 1 output layer\n",
    "model3 = Model(Inp, output)\n",
    "model3.summary() # We have 308,010 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "3da4e128-5987-4fb3-a2c7-93420c844d1d",
    "_execution_state": "busy",
    "_uuid": "304ab7710bc6f2e56d698cc232fadbba6886b664"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# We rely on 'Adam' as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "f7ac3e43-bf76-488d-8ec6-31ec98228ee6",
    "_execution_state": "busy",
    "_uuid": "986fc367bbd1fc9767c30a03324c4d18e3bfd0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 [==============================] - 6s 15ms/step - loss: 0.3620 - accuracy: 0.8921 - val_loss: 0.1664 - val_accuracy: 0.9479\n",
      "Epoch 2/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1231 - accuracy: 0.9623 - val_loss: 0.1223 - val_accuracy: 0.9618\n",
      "Epoch 3/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0838 - accuracy: 0.9733 - val_loss: 0.1313 - val_accuracy: 0.9638\n",
      "Epoch 4/20\n",
      "336/336 [==============================] - 5s 13ms/step - loss: 0.0630 - accuracy: 0.9795 - val_loss: 0.0959 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.1074 - val_accuracy: 0.9695\n",
      "Epoch 6/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0410 - accuracy: 0.9869 - val_loss: 0.0844 - val_accuracy: 0.9769\n",
      "Epoch 7/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 0.1439 - val_accuracy: 0.9639\n",
      "Epoch 8/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.1026 - val_accuracy: 0.9732\n",
      "Epoch 9/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 0.0952 - val_accuracy: 0.9745\n",
      "Epoch 10/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.1228 - val_accuracy: 0.9708\n",
      "Epoch 11/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0963 - val_accuracy: 0.9754\n",
      "Epoch 12/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.1044 - val_accuracy: 0.9758\n",
      "Epoch 13/20\n",
      "336/336 [==============================] - 6s 18ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.1091 - val_accuracy: 0.9750\n",
      "Epoch 14/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.1118 - val_accuracy: 0.9739\n",
      "Epoch 15/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.1231 - val_accuracy: 0.9713\n",
      "Epoch 16/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.1141 - val_accuracy: 0.9738\n",
      "Epoch 17/20\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1510 - val_accuracy: 0.9700\n",
      "Epoch 18/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.1330 - val_accuracy: 0.9732\n",
      "Epoch 19/20\n",
      "336/336 [==============================] - 7s 20ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.1294 - val_accuracy: 0.9755\n",
      "Epoch 20/20\n",
      "336/336 [==============================] - 7s 20ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.1178 - val_accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6d4f220-5431-4221-be1d-2a6ceae86ac9",
    "_execution_state": "idle",
    "_uuid": "595cd530b900cf25bb1774eabd22afff49b980df"
   },
   "source": [
    "Compared to our first model, adding an additional layer did not significantly improve the accuracy from our previous model. However, there are computational costs (in terms of complexity) in implementing an additional layer in our neural network. Given that the benefits of an additional layer are low while the costs are high, we will stick with the 4 layer neural network.\n",
    "\n",
    "We now proceed to include dropout (dropout rate of 0.3) in our second model to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "9054eb9b-e655-415c-93e7-3f0ca45d84ac",
    "_execution_state": "busy",
    "_uuid": "608b71d5bd8dc23df6d916e7371887fd52dd24d8"
   },
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "0541e860-b2f6-43cd-8d00-254e9daf775a",
    "_execution_state": "busy",
    "_uuid": "d6335bd113992a8898679d1a5d09ed2eda3fe5af"
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "95f4299a-0e1c-4dca-b7d5-839e7a5e8fc8",
    "_execution_state": "busy",
    "_uuid": "08e56562d89bcd25756bc5bbbb4f33ceb87f106e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " Hidden_Layer_1 (Dense)      (None, 300)               235500    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300)               0         \n",
      "                                                                 \n",
      " Hidden_Layer_2 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " Hidden_Layer_3 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " Hidden_Layer_4 (Dense)      (None, 200)               20200     \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 297910 (1.14 MB)\n",
      "Trainable params: 297910 (1.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model4 = Model(Inp, output)\n",
    "model4.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "ed1c4a9d-730e-4e4d-8a25-4448d877d5b6",
    "_execution_state": "busy",
    "_uuid": "2328fa07b0f4c63448b0c30b7ae450df2b0fe3be"
   },
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "8543232e-da2b-46ce-9a5e-06e6283b854a",
    "_execution_state": "busy",
    "_uuid": "986af85bbaf1b212b00cf28dc9204339b717ee48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "336/336 [==============================] - 9s 23ms/step - loss: 0.5839 - accuracy: 0.8125 - val_loss: 0.1982 - val_accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "336/336 [==============================] - 7s 22ms/step - loss: 0.2357 - accuracy: 0.9306 - val_loss: 0.1400 - val_accuracy: 0.9600\n",
      "Epoch 3/20\n",
      "336/336 [==============================] - 7s 21ms/step - loss: 0.1722 - accuracy: 0.9496 - val_loss: 0.1165 - val_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "336/336 [==============================] - 7s 22ms/step - loss: 0.1372 - accuracy: 0.9595 - val_loss: 0.1107 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1275 - accuracy: 0.9632 - val_loss: 0.1029 - val_accuracy: 0.9712\n",
      "Epoch 6/20\n",
      "336/336 [==============================] - 6s 17ms/step - loss: 0.1084 - accuracy: 0.9688 - val_loss: 0.1019 - val_accuracy: 0.9719\n",
      "Epoch 7/20\n",
      "336/336 [==============================] - 7s 20ms/step - loss: 0.0992 - accuracy: 0.9704 - val_loss: 0.0955 - val_accuracy: 0.9743\n",
      "Epoch 8/20\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.0884 - accuracy: 0.9730 - val_loss: 0.0876 - val_accuracy: 0.9756\n",
      "Epoch 9/20\n",
      "336/336 [==============================] - 6s 17ms/step - loss: 0.0835 - accuracy: 0.9760 - val_loss: 0.0917 - val_accuracy: 0.9764\n",
      "Epoch 10/20\n",
      "336/336 [==============================] - 8s 24ms/step - loss: 0.0717 - accuracy: 0.9788 - val_loss: 0.0869 - val_accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "336/336 [==============================] - 8s 23ms/step - loss: 0.0688 - accuracy: 0.9796 - val_loss: 0.0888 - val_accuracy: 0.9783\n",
      "Epoch 12/20\n",
      "336/336 [==============================] - 7s 20ms/step - loss: 0.0642 - accuracy: 0.9809 - val_loss: 0.0860 - val_accuracy: 0.9785\n",
      "Epoch 13/20\n",
      "336/336 [==============================] - 6s 19ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.0893 - val_accuracy: 0.9777\n",
      "Epoch 14/20\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0585 - accuracy: 0.9824 - val_loss: 0.0875 - val_accuracy: 0.9789\n",
      "Epoch 15/20\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.0547 - accuracy: 0.9842 - val_loss: 0.0892 - val_accuracy: 0.9792\n",
      "Epoch 16/20\n",
      "336/336 [==============================] - 5s 16ms/step - loss: 0.0566 - accuracy: 0.9835 - val_loss: 0.0792 - val_accuracy: 0.9805\n",
      "Epoch 17/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0447 - accuracy: 0.9857 - val_loss: 0.0808 - val_accuracy: 0.9795\n",
      "Epoch 18/20\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.0485 - accuracy: 0.9861 - val_loss: 0.0906 - val_accuracy: 0.9779\n",
      "Epoch 19/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0443 - accuracy: 0.9866 - val_loss: 0.0893 - val_accuracy: 0.9795\n",
      "Epoch 20/20\n",
      "336/336 [==============================] - 5s 14ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 0.0824 - val_accuracy: 0.9795\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(X_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = training_epochs,\n",
    "                    validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07d922d5-ec8a-4b3b-8e02-a0aafc3ad52a",
    "_execution_state": "idle",
    "_uuid": "ad316467bedf355759a181d353850f1d365ee05b"
   },
   "source": [
    "With a validation score of close to 98%, we proceed to use this model to predict for the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
